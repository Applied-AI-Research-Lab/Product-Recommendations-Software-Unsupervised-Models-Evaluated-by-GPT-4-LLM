{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjKp4BzRQ5ZdBA5sQCMRfH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"Rv_f_rFNkYSB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705817468488,"user_tz":-120,"elapsed":2497,"user":{"displayName":"Roumeliotis Konstadinos","userId":"17264923090131634662"}},"outputId":"6a7d0be1-9742-4fac-aad9-96ae12f78da2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Columns ['Recommendation', 'gptEvaluation'] removed successfully. Saved as: /content/gdrive/My Drive/Recommendation/Datasets/recommendations.csv\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import random\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","\n","def randomly_create_dataset(rows):\n","    # Load the original dataset\n","    original_dataset_path = '/content/gdrive/My Drive/Recommendation/Datasets/amz_uk_processed_data.csv'\n","    original_df = pd.read_csv(original_dataset_path)\n","\n","    # Randomly select 10,000 rows\n","    selected_rows = random.sample(range(len(original_df)), rows)\n","    new_dataset = original_df.iloc[selected_rows].copy()\n","\n","    # Create two new columns\n","    new_dataset['Recommendation'] = \"\"\n","    new_dataset['gptEvaluation'] = \"\"\n","\n","    # Save the new dataset\n","    new_dataset_path = '/content/gdrive/My Drive/Recommendation/Datasets/dataset.csv'\n","    new_dataset.to_csv(new_dataset_path, index=False)\n","\n","\n","def split_dataset():\n","    df = pd.read_csv('/content/gdrive/My Drive/Recommendation/Datasets/dataset.csv')  # Load the dataset\n","\n","    # Split the dataset into training (70%), validation (15%), and test (15%) sets\n","    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n","    valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n","\n","    # Save each split dataset to a CSV file\n","    train_df.to_csv(\"/content/gdrive/My Drive/Recommendation/Datasets/train_set.csv\", index=False)\n","    valid_df.to_csv(\"/content/gdrive/My Drive/Recommendation/Datasets/validation_set.csv\", index=False)\n","    test_df.to_csv(\"/content/gdrive/My Drive/Recommendation/Datasets/test_set.csv\", index=False)\n","\n","\n","def add_columns_to_csv(input_file_path, output_file_path, new_columns, default_value=None):\n","    # Read the CSV file into a pandas DataFrame\n","    df = pd.read_csv(input_file_path)\n","\n","    # Add new columns from the array\n","    for column_name in new_columns:\n","        df[column_name] = default_value\n","\n","    # Write the modified DataFrame to a new CSV file\n","    df.to_csv(output_file_path, index=False)\n","\n","\n","def remove_column_from_csv(file_path, columns_to_remove):\n","    # Read the CSV file into a pandas DataFrame\n","    df = pd.read_csv(file_path)\n","\n","    # Check if the specified columns exist\n","    non_existing_columns = [col for col in columns_to_remove if col not in df.columns]\n","    if non_existing_columns:\n","        print(f\"Columns {non_existing_columns} do not exist in the CSV file.\")\n","        return\n","\n","    # Remove the specified columns\n","    df = df.drop(columns=columns_to_remove)\n","\n","    # Get the directory and base filename\n","    directory, filename = os.path.split(file_path)\n","    filename_without_extension, extension = os.path.splitext(filename)\n","\n","    # Generate the new filename\n","    new_filename = f\"{filename_without_extension}{extension}\"\n","\n","    # Write the modified DataFrame to a new CSV file\n","    new_file_path = os.path.join(directory, new_filename)\n","    df.to_csv(new_file_path, index=False)\n","\n","    print(f\"Columns {columns_to_remove} removed successfully. Saved as: {new_file_path}\")\n","\n","\n","# Randomly create a new dataset\n","# randomly_create_dataset(10000)\n","# Split dataset to train, validation, test\n","# split_dataset()\n","# add_columns_to_csv(\"/content/gdrive/My Drive/Recommendation/Datasets/test_set.csv\", \"/content/gdrive/My Drive/Recommendation/Datasets/recommendations.csv\", ['kMeansRecommendation','kMeansEvaluation'])\n","# remove_column_from_csv(\"/content/gdrive/My Drive/Recommendation/Datasets/recommendations.csv\", ['Recommendation','gptEvaluation'])"]}]}